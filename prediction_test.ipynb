{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet152\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import progressbar\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = open(\"lamem/splits/train_1.txt\").readlines()\n",
    "f_test = open(\"lamem/splits/test_1.txt\").readlines()\n",
    "f_val = open(\"lamem/splits/val_1.txt\").readlines()\n",
    "\n",
    "X_train_list = [x[:12] for x in f_train]\n",
    "Y_train = np.array([float(x[13:21]) for x in f_train])\n",
    "\n",
    "X_test_list = [x[:12] for x in f_test]\n",
    "Y_test = np.array([float(x[13:21]) for x in f_test])\n",
    "\n",
    "X_val_list = [x[:12] for x in f_val]\n",
    "Y_val = np.array([float(x[13:21]) for x in f_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"Y.h5\", \"w\") as h5f:\n",
    "    for i in range(len(Y_train)):\n",
    "        h5f.create_dataset(X_train_list[i], data=Y_train[i])\n",
    "    for i in range(len(Y_test)):\n",
    "        h5f.create_dataset(X_test_list[i], data=Y_test[i])\n",
    "    for i in range(len(Y_val)):\n",
    "        h5f.create_dataset(X_val_list[i], data=Y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File(\"test_features.h5\")\n",
    "\n",
    "X_test_valide = [x in set(h5f.keys()) for x in X_test_list]\n",
    "X_train_list = [x for x, y in zip(X_test_list, X_test_valide) if y]\n",
    "Y_train = [x for x, y in zip(Y_test, X_test_valide) if y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n",
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# with h5py.File(\"train_features.h5\") as h5f:\n",
    "#     X_train = np.array([h5f[img][:] for img in X_train_list])\n",
    "h5f_train = h5py.File(\"train_features.h5\")\n",
    "h5f_test = h5py.File(\"test_features.h5\")\n",
    "X  = np.array([h5f_train[img][:] for img in list(h5f_train.keys())] + [h5f_test[img][:] for img in list(h5f_test.keys())])\n",
    "h5f2 = h5py.File(\"Y.h5\")\n",
    "Y  = np.array([h5f2[img].value for img in list(h5f_train.keys())+list(h5f_test.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52757, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(range(len(X)), test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    c, p = spearmanr(y_true, y_pred)\n",
    "    return c\n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS = {\n",
    "        'model': XGBRegressor(n_jobs=-1),\n",
    "        'params': {\n",
    "            \"n_estimators\": [100, 150, 200], # 'poly', 'sigmoid'\n",
    "            \"max_depth\": [4, 5, 6],\n",
    "            \"eta\": [0.01],\n",
    "        }\n",
    "    }\n",
    "CV = 3\n",
    "model = GridSearchCV(\n",
    "        ALGORITHMS['model'],\n",
    "        ALGORITHMS['params'],\n",
    "        cv=CV,\n",
    "        scoring=score,\n",
    "        n_jobs=-1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constrain...\n",
       "                                    random_state=None, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'eta': [0.01], 'max_depth': [4, 5, 6],\n",
       "                         'n_estimators': [100, 150, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(my_custom_loss_func), verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[:7000], Y[:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.00999999978, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=200, n_jobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(n_jobs=-1, n_estimators=200, max_depth=8, eta=0.01)\n",
    "model.fit(X[:7000], Y[:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmanr Result: correlation: 0.59634, p-value: 4.339106950756918e-74\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X[7000:])\n",
    "c, p = spearmanr(Y[7000:], pred)\n",
    "\n",
    "print(\"Spearmanr Result: correlation: {:.5f}, p-value: {}\".format(c, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "ALGORITHMS = {\n",
    "        'model': SVR(gamma='scale'),\n",
    "        'params': {\n",
    "            \"kernel\": ['rbf', 'sigmoid'], # 'poly', 'sigmoid'\n",
    "            \"C\": [0.1, 1.0, 10.0],\n",
    "            \"epsilon\": [0.001, 1.0],\n",
    "        }\n",
    "    }\n",
    "\n",
    "CV = 3\n",
    "model = GridSearchCV(\n",
    "        ALGORITHMS['model'],\n",
    "        ALGORITHMS['params'],\n",
    "        cv=CV,\n",
    "        scoring=score,\n",
    "        n_jobs=-1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(gamma='scale', kernel=\"rbf\", C=1.0, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X[train_set], Y[train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X[test_set])\n",
    "c, p = spearmanr(Y[test_set], pred)\n",
    "\n",
    "print(\"Spearmanr Result: correlation: {:.5f}, p-value: {}\".format(c, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jojo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"test_features_new.h5\", 'w') as h5f2:\n",
    "    for i in set(h5f.keys()):\n",
    "        try:\n",
    "            h5f2.create_dataset(i, data=h5f[i].value)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.backend import expand_dims\n",
    "from keras.losses import MeanSquaredLogarithmicError\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "def correlation_loss(x, y):    \n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = tf.math.reduce_mean(tf.multiply(xm,ym))        \n",
    "    r_den = tf.math.reduce_std(xm) * tf.math.reduce_std(ym)\n",
    "    return 5 * MSE(x,y) - r_num / r_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = (Y-np.mean(Y))/np.std(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature = Input(shape=(2048,), name='Input')\n",
    "x = Dense(256, activation='sigmoid')(input_feature)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='sigmoid')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_feature, x)\n",
    "model.compile(optimizer='adam', loss=correlation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.8278 - val_loss: 3.6755\n",
      "Epoch 2/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.5339 - val_loss: 3.6340\n",
      "Epoch 3/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.4715 - val_loss: 3.6092\n",
      "Epoch 4/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.4313 - val_loss: 3.5816\n",
      "Epoch 5/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.3912 - val_loss: 3.5776\n",
      "Epoch 6/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.3646 - val_loss: 3.5686\n",
      "Epoch 7/20\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 3.3329 - val_loss: 3.5700\n",
      "Epoch 8/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.3072 - val_loss: 3.5827\n",
      "Epoch 9/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.2774 - val_loss: 3.5800\n",
      "Epoch 10/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.2581 - val_loss: 3.5853\n",
      "Epoch 11/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.2185 - val_loss: 3.5881\n",
      "Epoch 12/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.1946 - val_loss: 3.5808\n",
      "Epoch 13/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.1757 - val_loss: 3.5743\n",
      "Epoch 14/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.1528 - val_loss: 3.5868\n",
      "Epoch 15/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.1251 - val_loss: 3.5922\n",
      "Epoch 16/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.1007 - val_loss: 3.5940\n",
      "Epoch 17/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.0848 - val_loss: 3.5861\n",
      "Epoch 18/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.0643 - val_loss: 3.6337\n",
      "Epoch 19/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.0363 - val_loss: 3.5995\n",
      "Epoch 20/20\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 3.0194 - val_loss: 3.6110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba4831b9d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[train_set], Y_new[train_set], batch_size=256, epochs=20, validation_data=(X[test_set], Y_new[test_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmanr Result: correlation: 0.66295, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X[test_set])\n",
    "c, p = spearmanr(Y_new[test_set], pred)\n",
    "\n",
    "print(\"Spearmanr Result: correlation: {:.5f}, p-value: {}\".format(c, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet152(weights=\"imagenet\", include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=(224, 224)\n",
    "image = load_img(\"frame/dyson1.mp4-frame-200.jpg\", target_size=IMG_SIZE)\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78836733]], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7 (default, May  6 2020, 04:59:01) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)] \n",
      "\n",
      "PyTorch 1.5.0 \n",
      "\n",
      "Torch-vision 0.6.0 \n",
      "\n",
      "Available devices:\n",
      "CPUs only, no GPUs found\n"
     ]
    }
   ],
   "source": [
    "# Regular Python libraries\n",
    "import sys\n",
    "from collections import deque #\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "from time import sleep, time\n",
    "from threading import Thread\n",
    "from IPython.display import Video\n",
    "\n",
    "# Third party tools\n",
    "import decord #\n",
    "import IPython.display #\n",
    "from ipywebrtc import CameraStream, ImageRecorder\n",
    "from ipywidgets import HBox, HTML, Layout, VBox, Widget, Label\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "# utils_cv\n",
    "sys.path.append(\"../../\")\n",
    "from utils_cv.action_recognition.data import KINETICS, Urls\n",
    "from utils_cv.action_recognition.dataset import get_transforms\n",
    "from utils_cv.action_recognition.model import VideoLearner\n",
    "from utils_cv.action_recognition.references import transforms_video as transforms\n",
    "from utils_cv.common.gpu import system_info, torch_device\n",
    "from utils_cv.common.data import data_path\n",
    "\n",
    "system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 32  # 8 or 32.\n",
    "IM_SCALE = 128  # resize then crop\n",
    "INPUT_SIZE = 112  # input clip size: 3 x NUM_FRAMES x 112 x 112\n",
    "\n",
    "\n",
    "# prediction score threshold\n",
    "SCORE_THRESHOLD = 0.01\n",
    "\n",
    "# Averaging 5 latest clips to make video-level prediction (or smoothing)\n",
    "AVERAGING_SIZE = 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
